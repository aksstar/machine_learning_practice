{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "957a2e39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Gramformer] Grammar error correct/highlight model loaded..\n",
      "[Input]  He are moving here.\n",
      "[Correction]  ('He is moving here.', -31.028507232666016)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[Input]  the collection of letters was original used by the ancient Romans\n",
      "[Correction]  ('the collection of letters was originally used by the ancient Romans.', -58.17930603027344)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[Input]  We enjoys horror movies\n",
      "[Correction]  ('We enjoy horror movies.', -31.771575927734375)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[Input]  Anna and Mike is going skiing\n",
      "[Correction]  ('Anna and Mike are going skiing.', -42.59700012207031)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[Input]  I will eat fish for dinner and drank milk\n",
      "[Correction]  ('I ate fish for dinner and drank milk.', -45.50601577758789)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[Input]  what be the reason for everyone leave the comapny\n",
      "[Correction]  ('what is the reason for everyone leaving the community?', -45.469337463378906)\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from gramformer import Gramformer\n",
    "\n",
    "# set_seed(1212)\n",
    "\n",
    "gf = Gramformer(models = 1, use_gpu=False) # 1=corrector, 2=detector\n",
    "\n",
    "\n",
    "influent_sentences = [\n",
    "    \"He are moving here.\",\n",
    "    \"the collection of letters was original used by the ancient Romans\",\n",
    "    \"We enjoys horror movies\",\n",
    "    \"Anna and Mike is going skiing\",\n",
    "    \"I will eat fish for dinner and drank milk\",\n",
    "    \"what be the reason for everyone leave the comapny\"\n",
    "]   \n",
    "\n",
    "for influent_sentence in influent_sentences:\n",
    "    corrected_sentences = gf.correct(influent_sentence, max_candidates=1)\n",
    "    print(\"[Input] \", influent_sentence)\n",
    "    for corrected_sentence in corrected_sentences:\n",
    "      print(\"[Correction] \",corrected_sentence)\n",
    "    print(\"-\" *100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ded2148c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Requirement already satisfied: docx2python in ./gramformer-env/lib/python3.7/site-packages (1.27.1)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.2; however, version 21.2.4 is available.\n",
      "You should consider upgrading via the '/Users/aakashgouda/Python_Project/Untitled Folder/gramformer-env/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install docx2python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a5908451",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mammoth\n",
    "with open(\"EMR blog.docx\", \"rb\") as docx_file:\n",
    "    result = mammoth.convert_to_html(docx_file)\n",
    "with open(\"sample.html\", \"w\") as html_file:\n",
    "    html_file.write(result.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "982d1ea0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Input]  He are moving here.\n",
      "[Edits]  He <c type='VERB:SVA' edit='is'>are</c> moving here.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[Input]  the collection of letters was original used by the ancient Romans\n",
      "[Edits]  <c type='ORTH' edit='The'>the</c> collection of letters was <c type='MORPH' edit='originally'>original</c> used by the ancient Romans\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[Input]  We enjoys horror movies\n",
      "[Edits]  We <c type='VERB:SVA' edit='enjoy'>enjoys</c> horror movies\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[Input]  Anna and Mike is going skiing\n",
      "[Edits]  Anna and Mike <c type='VERB:SVA' edit='are'>is</c> going <c type='OTHER' edit='skiing.'>skiing</c>\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[Input]  I will eat fish for dinner and drank milk\n",
      "[Edits]  I <c type='VERB:TENSE' edit='ate'>will eat</c> fish for dinner and drank <c type='NOUN' edit='milk.'>milk</c>\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[Input]  what be the reason for everyone leave the comapny\n",
      "[Edits]  what be the reason for everyone <c type='VERB:FORM' edit='leaving'>leave</c> the <c type='NOUN' edit='community.'>comapny</c>\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "influent_sentences = [\n",
    "    \"He are moving here.\",\n",
    "    \"the collection of letters was original used by the ancient Romans\",\n",
    "    \"We enjoys horror movies\",\n",
    "    \"Anna and Mike is going skiing\",\n",
    "    \"I will eat fish for dinner and drank milk\",\n",
    "    \"what be the reason for everyone leave the comapny\"\n",
    "]   \n",
    "\n",
    "for influent_sentence in influent_sentences:\n",
    "    corrected_sentences = gf.correct(influent_sentence, max_candidates=1)\n",
    "    print(\"[Input] \", influent_sentence)\n",
    "    for corrected_sentence in corrected_sentences:\n",
    "      print(\"[Edits] \", gf.highlight(influent_sentence, corrected_sentence[0]))\n",
    "    print(\"-\" *100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b041d6d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
